{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Case2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM7fBersZ1pK9LYj024tbiE"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"ito8rzHt83ui","colab_type":"code","colab":{}},"source":["!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n","!wget -q https://downloads.apache.org/spark/spark-3.0.0-preview2/spark-3.0.0-preview2-bin-hadoop2.7.tgz\n","!tar -xvf spark-3.0.0-preview2-bin-hadoop2.7.tgz\n","!pip install -q findspark\n","import os\n","os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n","os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.0-preview2-bin-hadoop2.7\"\n","import findspark\n","findspark.init()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"inSm2k8HmEhh","colab_type":"code","outputId":"8a4f311e-9ec2-4c3f-bf04-d966b478cc7b","executionInfo":{"status":"ok","timestamp":1592291280096,"user_tz":-420,"elapsed":21778,"user":{"displayName":"Octavianus Liemka","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiBwM4Op7lQDUUm_kpgEdF3y1hO4RFwJ48mgXNb=s64","userId":"14040030465003185990"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import when\n","from pyspark.ml.feature import VectorAssembler,StandardScaler\n","from pyspark.ml.classification import LogisticRegression\n","from pyspark.ml.evaluation import BinaryClassificationEvaluator\n","\n","spark = SparkSession.builder.getOrCreate()\n","\n","df_train = spark.read.option(\"inferschema\",\"true\").csv(\"Planet_Training.csv\", header=True)\n","df_train = df_train.select(\"Temperature\", \"Atmosphere Color\", \"Water\", \"Habitable\")\n","df_train = df_train.na.drop()\n","df_train = df_train.withColumn(\"Atmosphere Color\", when(df_train[\"Atmosphere Color\"] == \"Red\", 0).when(df_train[\"Atmosphere Color\"]==\"Blue\",1).otherwise(2))\n","df_train = df_train.withColumn(\"Water\", when(df_train[\"Water\"] == \"Low\", 0).when(df_train[\"Water\"]==\"Medium\",1).otherwise(2))\n","\n","col_train = df_train.columns\n","col_train.remove(\"Habitable\")\n","df_train = VectorAssembler(inputCols = col_train, outputCol = \"Features\").transform(df_train)\n","\n","scaler_train = StandardScaler(inputCol = \"Features\", outputCol=\"Scaled_Features\")\n","df_train = scaler_train.fit(df_train).transform(df_train)\n","\n","df_test = spark.read.option(\"inferSchema\",\"true\").csv(\"Planet_Testing.csv\", header=True)\n","df_test = df_test.select(\"Temperature\", \"Atmosphere Color\", \"Water\", \"Habitable\")\n","df_test = df_test.na.drop()\n","df_test = df_test.withColumn(\"Atmosphere Color\", when(df_test[\"Atmosphere Color\"] == \"Red\", 0).when(df_test[\"Atmosphere Color\"]==\"Blue\",1).otherwise(2))\n","df_test = df_test.withColumn(\"Water\", when(df_test[\"Water\"] == \"Low\", 0).when(df_test[\"Water\"]==\"Medium\",1).otherwise(2))\n","\n","col_test = df_test.columns\n","col_test.remove(\"Habitable\")\n","df_test = VectorAssembler(inputCols = col_test, outputCol = \"Features\").transform(df_test)\n","\n","scaler_test = StandardScaler(inputCol = \"Features\", outputCol=\"Scaled_Features\")\n","df_test = scaler_test.fit(df_test).transform(df_test)\n","\n","model = LogisticRegression(featuresCol = \"Scaled_Features\", labelCol = \"Habitable\", maxIter = 10).fit(df_train)\n","prediction = model.transform(df_test)\n","\n","evaluator = BinaryClassificationEvaluator(rawPredictionCol = \"rawPrediction\", labelCol = \"Habitable\")\n","print(\"Accuracy: {}%\".format(evaluator.evaluate(prediction)*100))\n"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Accuracy: 91.71043337232418%\n"],"name":"stdout"}]}]}